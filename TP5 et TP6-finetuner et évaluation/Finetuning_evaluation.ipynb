{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d11ff7-a29f-4c49-bed9-7fffe67ec161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867df8dbc2f243c1be8ae6e4be8ad43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b5b70aee734a94817f384b979f0002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 01:26, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24591509997844696, 'eval_accuracy': 0.95, 'eval_runtime': 2.9169, 'eval_samples_per_second': 6.857, 'eval_steps_per_second': 1.029, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af815c7d2cf74a71ad5206ef2b7f2bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/76 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10672b6657b543d9b72b1d2d20922593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 01:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6642757654190063, 'eval_accuracy': 0.8, 'eval_runtime': 2.9151, 'eval_samples_per_second': 6.861, 'eval_steps_per_second': 1.029, 'epoch': 2.0}\n",
      "Modèles sauvegardés avec succès.\n",
      "\n",
      "Évaluation complète des modèles :\n",
      "\n",
      "| Modèle                  |   Accuracy |   Precision |   Recall |   F1-score |     Loss |   Temps (s) |\n",
      "|:------------------------|-----------:|------------:|---------:|-----------:|---------:|------------:|\n",
      "| Classification binaire  |       0.95 |      0.9025 |     0.95 |   0.925641 | 0.245915 |      2.8112 |\n",
      "| Classification sévérité |       0.8  |      0.64   |     0.8  |   0.711111 | 0.664276 |      3.0152 |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script d'entraînement de modèles CamemBERT pour la classification de synopsis de films d'horreur.\n",
    "\n",
    "Ce script entraîne deux modèles de classification de texte en français, basés sur CamemBERT :\n",
    "1. Un modèle binaire (horreur vs non-horreur)\n",
    "2. Un modèle à trois classes (niveau de sévérité : 0 = neutre, 1 = modéré, 2 = intense)\n",
    "\n",
    "Les données sont issues d’un fichier CSV contenant les textes annotés, produit par un script d’analyse lexicale\n",
    "basé sur un dictionnaire de mots-clés horreur.\n",
    "\n",
    "Fonctionnalités :\n",
    "-----------------\n",
    "- Chargement du dataset `dataset_horreur.csv`\n",
    "- Séparation entraînement/test (20%)\n",
    "- Tokenisation avec `CamembertTokenizer`\n",
    "- Entraînement de deux modèles `CamembertForSequenceClassification`\n",
    "- Évaluation automatique (accuracy, précision, rappel, F1, perte, temps)\n",
    "- Sauvegarde des modèles et des résultats\n",
    "\n",
    "Bibliothèques utilisées :\n",
    "-------------------------\n",
    "- pandas\n",
    "- datasets (Hugging Face)\n",
    "- transformers (Hugging Face)\n",
    "- torch\n",
    "- evaluate\n",
    "- numpy\n",
    "- scikit-learn (pour les métriques avancées)\n",
    "\n",
    "Structure de sortie :\n",
    "---------------------\n",
    "- Dossiers `./camembert_binary` et `./camembert_severity` contenant les modèles entraînés.\n",
    "- Dossier `./results_bin` et `./results_sev` pour les logs de chaque entraînement.\n",
    "- Fichier `resultats_evaluation.csv` résumant les performances des deux modèles.\n",
    "- Affichage console au format markdown.\n",
    "\n",
    "Pré-requis :\n",
    "------------\n",
    "- Avoir exécuté le script d’annotation pour générer `dataset_horreur.csv`\n",
    "- Environnement Python avec les dépendances installées :\n",
    "    pip install pandas datasets transformers evaluate scikit-learn torch\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Import des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ----------- CHARGEMENT DES DONNÉES -----------\n",
    "# Lecture du fichier CSV contenant les synopsis et les labels\n",
    "df = pd.read_csv('../TP4-augmentation_donnés/dataset_horreur.csv')\n",
    "\n",
    "# ----------- CLASSIFICATION BINAIRE (Horreur ou non) -----------\n",
    "# On ne garde que la colonne de texte et le label binaire\n",
    "df_bin = df[['text', 'label_binary']].rename(columns={'label_binary': 'label'})\n",
    "# Conversion en format Dataset Hugging Face\n",
    "dataset_bin = Dataset.from_pandas(df_bin)\n",
    "# Division en jeu d'entraînement et de test (80%/20%)\n",
    "dataset_bin = dataset_bin.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Chargement du tokenizer CamemBERT\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "\n",
    "# Fonction de prétraitement : tokenisation et padding/troncature\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "# Application de la tokenisation au jeu de données\n",
    "encoded_bin = dataset_bin.map(preprocess_function, batched=True)\n",
    "\n",
    "# Chargement du modèle CamemBERT avec 2 classes (binaire)\n",
    "model_bin = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels=2)\n",
    "\n",
    "# Fonction d'évaluation pour calculer la précision\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "# Définition des arguments d'entraînement\n",
    "training_args_bin = TrainingArguments(\n",
    "    output_dir='./results_bin',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./logs_bin',\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# Entraîneur Hugging Face pour la classification binaire\n",
    "trainer_bin = Trainer(\n",
    "    model=model_bin,\n",
    "    args=training_args_bin,\n",
    "    train_dataset=encoded_bin['train'],\n",
    "    eval_dataset=encoded_bin['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Entraînement du modèle\n",
    "trainer_bin.train()\n",
    "# Évaluation sur le jeu de test\n",
    "print(trainer_bin.evaluate())\n",
    "\n",
    "# ----------- CLASSIFICATION PAR NIVEAU DE SÉVÉRITÉ (0, 1, 2) -----------\n",
    "# Préparation des données pour la classification à 3 classes\n",
    "df_sev = df[['text', 'label_severity']].rename(columns={'label_severity': 'label'})\n",
    "dataset_sev = Dataset.from_pandas(df_sev)\n",
    "dataset_sev = dataset_sev.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Application de la tokenisation\n",
    "encoded_sev = dataset_sev.map(preprocess_function, batched=True)\n",
    "\n",
    "# Chargement du modèle pour 3 classes\n",
    "model_sev = CamembertForSequenceClassification.from_pretrained('camembert-base', num_labels=3)\n",
    "\n",
    "# Définition des arguments d'entraînement pour la classification de sévérité\n",
    "training_args_sev = TrainingArguments(\n",
    "    output_dir='./results_sev',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./logs_sev',\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "# Entraîneur pour la classification par sévérité\n",
    "trainer_sev = Trainer(\n",
    "    model=model_sev,\n",
    "    args=training_args_sev,\n",
    "    train_dataset=encoded_sev['train'],\n",
    "    eval_dataset=encoded_sev['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Entraînement et évaluation\n",
    "trainer_sev.train()\n",
    "print(trainer_sev.evaluate())\n",
    "\n",
    "# ----------- SAUVEGARDE DES MODÈLES -----------\n",
    "# Sauvegarde du modèle binaire\n",
    "model_bin.save_pretrained(\"./camembert_binary\")\n",
    "tokenizer.save_pretrained(\"./camembert_binary\")\n",
    "\n",
    "# Sauvegarde du modèle de sévérité\n",
    "model_sev.save_pretrained(\"./camembert_severity\")\n",
    "tokenizer.save_pretrained(\"./camembert_severity\")\n",
    "\n",
    "print(\"Modèles sauvegardés avec succès.\")\n",
    "\n",
    "# ----------- ÉVALUATION COMPLÈTE AVEC MÉTRIQUES DÉTAILLÉES -----------\n",
    "\n",
    "# Fonction qui calcule plusieurs métriques sur un jeu de données\n",
    "def compute_all_metrics(trainer, dataset, average=\"weighted\"):\n",
    "    predictions = trainer.predict(dataset)\n",
    "    preds = np.argmax(predictions.predictions, axis=1)\n",
    "    labels = predictions.label_ids\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(labels, preds),\n",
    "        \"Precision\": precision_score(labels, preds, average=average, zero_division=0),\n",
    "        \"Recall\": recall_score(labels, preds, average=average, zero_division=0),\n",
    "        \"F1-score\": f1_score(labels, preds, average=average, zero_division=0),\n",
    "        \"Loss\": predictions.metrics.get(\"test_loss\", predictions.metrics.get(\"eval_loss\")),\n",
    "        \"Temps (s)\": predictions.metrics.get(\"test_runtime\", predictions.metrics.get(\"eval_runtime\"))\n",
    "    }\n",
    "\n",
    "# Évaluation des deux modèles\n",
    "metrics_bin = compute_all_metrics(trainer_bin, encoded_bin[\"test\"])\n",
    "metrics_sev = compute_all_metrics(trainer_sev, encoded_sev[\"test\"])\n",
    "\n",
    "# ----------- AFFICHAGE ET SAUVEGARDE DES RÉSULTATS -----------\n",
    "\n",
    "# Création d’un tableau de résultats avec pandas\n",
    "results_df = pd.DataFrame([\n",
    "    {\"Modèle\": \"Classification binaire\", **metrics_bin},\n",
    "    {\"Modèle\": \"Classification sévérité\", **metrics_sev},\n",
    "])\n",
    "\n",
    "# Affichage des résultats au format markdown dans la console\n",
    "print(\"\\nÉvaluation complète des modèles :\\n\")\n",
    "print(results_df.to_markdown(index=False))\n",
    "\n",
    "# Sauvegarde dans un fichier CSV\n",
    "results_df.to_csv(\"resultats_evaluation.csv\", index=False, encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a58a1-8d24-4b26-a68c-b7b4ed4471c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "mon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
